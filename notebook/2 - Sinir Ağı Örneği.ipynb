{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AB2018 Derin Öğrenme Atölyesi - Sinir Ağı Örneği\n",
    "\n",
    "Bu örnekte Tensorflow kullanarak bir sinir ağı oluşturacağız ve MNIST verisetinde sınıflandırma yapacağız. Başlangıç kısmı, bir önceki örnekle neredeyse aynı, bu nedenle hızlıca geçeceğim. İlk iş gerekli paketleri içe aktarıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST verisetini indiriyor ve kullanıma hazır hale getiriyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resimleri göstermek için basit bir yardımcı fonksiyon oluşturuyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_digit(pixels):\n",
    "    img = pixels.reshape(28, 28)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Önceki örnekte, verisetine kısaca bir gözatmıştık. Burada doğrudan modeli oluşturmaya başlayalım. İlk iş, veri girişini sağlayacak yer tutucuları oluşturuyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Önceki örnekten farklı olarak bu sefer modelde gizli katmanlar (hidden layer) kullanacağız. Tüm katmanlar için gerekli değişkenleri oluşturmamız lazım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_hidden1 = tf.Variable(tf.truncated_normal(shape=[784, 256], stddev=0.1))\n",
    "b_hidden1 = tf.Variable(tf.constant(shape=[256], value=0.1))\n",
    "\n",
    "W_hidden2 = tf.Variable(tf.truncated_normal(shape=[256, 128], stddev=0.1))\n",
    "b_hidden2 = tf.Variable(tf.constant(shape=[128], value=0.1))\n",
    "\n",
    "W_output = tf.Variable(tf.truncated_normal(shape=[128, 10], stddev=0.1))\n",
    "b_output = tf.Variable(tf.constant(shape=[10], value=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Değişkenlerin boyutlarından anlaşılacağı üzere, modelde 2 tane gizli katman mevcut (256 ve 128 nöronluk). Şimdi bunları kullanarak tahmin fonksiyonunu (grafını) oluşturmamız lazım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit1 = tf.matmul(X, W_hidden1) + b_hidden1\n",
    "activ1 = tf.nn.sigmoid(logit1)\n",
    "\n",
    "logit2 = tf.matmul(activ1, W_hidden2) + b_hidden2\n",
    "activ2 = tf.nn.sigmoid(logit2)\n",
    "\n",
    "logit3 = tf.matmul(activ2, W_output) + b_output\n",
    "y_pred = tf.nn.softmax(logit3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her bir katman, kendisine gelen girdilerle **logit** hesabını yapıyor ve çıkan değerleri bir aktivasyon fonksiyonuna veriyor. Bu aktivasyon fonksiyonları sayesinde çıkan değerleri modifiye etmek mümkün olacak. Gizli katmanlarda kullandığımız **sigmoid** fonksiyonu, kendisine gelen değerleri 0 ile 1 arasına çekecek. Son çıktı katmanında ise, olasılık değerlerini üretmek için **softmax** fonksiyonunu kullandık.\n",
    "\n",
    "Buradan sonrası, önceki örnekle neredeyse aynı, bu nedenle fazla detaya girmeyeceğim. Hemen kayıp (loss) fonksiyonunu tanımlayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_pred), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sonrasında optimizasyon aracı gerekecek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sistemin hassiyetini hesaplamak için bir graf daha oluşturuyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y, 1), tf.argmax(y_pred, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow oturumunu oluşturalım ve değişkenlerin ilk değerlerini verelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir önceki örnekten farklı olarak, bu sefer modeli daha fazla eğitmemiz gerekecek. Zira optimize edilmesi gerekilen çok daha fazla değişken var."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Adım: 0, batch kaybı: 2.643961, batch hassasiyeti: 6.25%\n",
      "[*] Adım: 3000, batch kaybı: 0.314838, batch hassasiyeti: 91.41%\n",
      "[*] Adım: 6000, batch kaybı: 0.266546, batch hassasiyeti: 92.19%\n",
      "[*] Adım: 9000, batch kaybı: 0.186936, batch hassasiyeti: 95.31%\n",
      "[*] Adım: 12000, batch kaybı: 0.300896, batch hassasiyeti: 92.97%\n",
      "[*] Adım: 15000, batch kaybı: 0.261727, batch hassasiyeti: 92.19%\n",
      "[*] Adım: 18000, batch kaybı: 0.084483, batch hassasiyeti: 98.44%\n",
      "[*] Adım: 21000, batch kaybı: 0.150009, batch hassasiyeti: 96.88%\n",
      "[*] Adım: 24000, batch kaybı: 0.113441, batch hassasiyeti: 96.88%\n",
      "[*] Adım: 27000, batch kaybı: 0.136246, batch hassasiyeti: 94.53%\n",
      "[*] Adım: 30000, batch kaybı: 0.208626, batch hassasiyeti: 92.97%\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(30001):\n",
    "    xs, ys = mnist.train.next_batch(128)\n",
    "    \n",
    "    _, batch_loss, batch_acc = sess.run([optimizer, loss, accuracy], feed_dict={X: xs, y: ys})\n",
    "    \n",
    "    if i % 3000 == 0:\n",
    "        print(\"[*] Adım: %d, batch kaybı: %.6f, batch hassasiyeti: %.2f%%\" % (i, batch_loss, batch_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin hassasiyetine gözatalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eğitim hassasiyeti: 96.29%, Test hassasiyeti: 95.88%\n"
     ]
    }
   ],
   "source": [
    "train_acc = sess.run(accuracy, feed_dict={X: mnist.train.images, y: mnist.train.labels})\n",
    "test_acc = sess.run(accuracy, feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "print(u\"Eğitim hassasiyeti: %.2f%%, Test hassasiyeti: %.2f%%\" % (train_acc * 100, test_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Önceki modele göre hassasiyet bir miktar artmış ama azıcık da overfitting'e yakalanmışız. Şimdi resimler üzerinden tahminlere gözatalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resmin 0 olma ihtimali: 0.00%\n",
      "Resmin 1 olma ihtimali: 0.07%\n",
      "Resmin 2 olma ihtimali: 0.10%\n",
      "Resmin 3 olma ihtimali: 99.22%\n",
      "Resmin 4 olma ihtimali: 0.00%\n",
      "Resmin 5 olma ihtimali: 0.21%\n",
      "Resmin 6 olma ihtimali: 0.00%\n",
      "Resmin 7 olma ihtimali: 0.00%\n",
      "Resmin 8 olma ihtimali: 0.39%\n",
      "Resmin 9 olma ihtimali: 0.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJjxD8aQOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x317149710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = random.choice(mnist.test.images)\n",
    "\n",
    "predictions = sess.run(y_pred, feed_dict={X: [sample] })[0]\n",
    "\n",
    "for i, v in enumerate(predictions):\n",
    "    print(u\"Resmin %d olma ihtimali: %.2f%%\" % (i, v * 100))\n",
    "    \n",
    "show_digit(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin eğitimi diğer modele göre oldukça uzun sürdü. Bu süreyi kısaltmanın bir yolu, farklı optimizasyon sistemleri denenemek. Şimdi gelin **AdadeltaOptimizer** adlı aracı deneyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Adım: 0, batch kaybı: 2.443028, batch hassasiyeti: 9.38%\n",
      "[*] Adım: 1000, batch kaybı: 0.306575, batch hassasiyeti: 94.53%\n",
      "[*] Adım: 2000, batch kaybı: 0.201096, batch hassasiyeti: 92.97%\n",
      "[*] Adım: 3000, batch kaybı: 0.212247, batch hassasiyeti: 91.41%\n",
      "[*] Adım: 4000, batch kaybı: 0.112714, batch hassasiyeti: 98.44%\n",
      "[*] Adım: 5000, batch kaybı: 0.138674, batch hassasiyeti: 96.09%\n",
      "[*] Adım: 6000, batch kaybı: 0.136950, batch hassasiyeti: 93.75%\n",
      "[*] Adım: 7000, batch kaybı: 0.103945, batch hassasiyeti: 96.88%\n",
      "[*] Adım: 8000, batch kaybı: 0.062237, batch hassasiyeti: 97.66%\n",
      "[*] Adım: 9000, batch kaybı: 0.098965, batch hassasiyeti: 98.44%\n",
      "[*] Adım: 10000, batch kaybı: 0.156161, batch hassasiyeti: 98.44%\n",
      "\n",
      "Eğitim hassasiyeti: 97.97%, Test hassasiyeti: 96.92%\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdadeltaOptimizer(1.0).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in xrange(10001):\n",
    "    xs, ys = mnist.train.next_batch(128)\n",
    "    \n",
    "    _, batch_loss, batch_acc = sess.run([optimizer, loss, accuracy], feed_dict={X: xs, y: ys})\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(\"[*] Adım: %d, batch kaybı: %.6f, batch hassasiyeti: %.2f%%\" % (i, batch_loss, batch_acc * 100))\n",
    "        \n",
    "train_acc = sess.run(accuracy, feed_dict={X: mnist.train.images, y: mnist.train.labels})\n",
    "test_acc = sess.run(accuracy, feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "print(u\"\\nEğitim hassasiyeti: %.2f%%, Test hassasiyeti: %.2f%%\" % (train_acc * 100, test_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Görüldüğü üzere, daha farklı bir optimizasyon aracı kullanarak daha yüksek bir hassasiyete ulaştık. Hem de daha az eğitim döngüsüyle. Çözülmesi istenen probleme göre, uygun bir optimizasyon sistemi kullanmak hem eğitim zamanını azaltabilir hem de hassasiyeti yükseltebilir. Tensorflow'da kullanabileceğiniz optimizasyon araçlarına gözatmak için [bu sayfaya](https://www.tensorflow.org/api_docs/python/tf/train) gözatabilirsiniz."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
